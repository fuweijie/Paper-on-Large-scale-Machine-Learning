# Paper-on-Large-scale-Machine-Learning
### The following are some suggeestions for papers on large scale machine learning.
### Surveys
O. Y. Al-Jarrah, P. D. Yoo, S. Muhaidat, G. K. Karagiannidis, and K. Taha, “Efficient machine learning for big data: A review,” Big Data Research, vol. 2, no. 3, pp. 87–93, 2015.

L. Bottou, F. E. Curtis, and J. Nocedal, “Optimization methods for large-scale machine learning,” SIAM Review, vol. 60, no. 2, pp. 223–311, 2018.

C.-W. Tsai, C.-F. Lai, H.-C. Chao, and A. V. Vasilakos, “Big data analytics: a survey,” Journal of Big data, vol. 2, no. 1, p. 21, 2015.

S. Landset, T. M. Khoshgoftaar, A. N. Richter, and T. Hasanin, “A survey of open source tools for machine learning with big data in the hadoop ecosystem,” Journal of Big Data, vol. 2, no. 1, p. 24, 2015.

### We present a comprehensive overview of LML according to three computational perspectives:
1) model simplification, which reduces computational complexities by simplifying predictive models; 
2) optimization approximation, which enhances computational efficiency by designing better optimization algorithms; 
3) computation parallelism, which improves computational capabilities by scheduling multiple computing devices.
## Model Simplification.
### Kernel-based Models
S. Kumar, M. Mohri, and A. Talwalkar, “Sampling methods for the nystrom method,” JMLR, vol. 13, no. Apr, pp. 981–1006, 2012.

T. Yang, Y.-F. Li, M. Mahdavi, R. Jin, and Z.-H. Zhou, “Nystrom method vs random fourier features: A theoretical and empirical comparison,” in Advances in neural information processing systems, 2012, pp. 476–484.

K. Zhang, L. Lan, J. T. Kwok, S. Vucetic, and B. Parvin, “Scaling up graph-based semisupervised learning via prototype vector machines,” IEEE TNNLS, vol. 26, no. 3, pp. 444–457, 2015.

D. Bouneffouf and I. Birol, “Sampling with minimum sum of squared similarities for nystrom-based large scale spectral clustering.” in Proceedings of IJCAI, 2015, pp. 2313–2319.

A. Farahat, A. Ghodsi, and M. Kamel, “A novel greedy algorithm for nystrom approximation,” in Proceedings of AISTATS, 2011, pp. 269–277.

K. Zhang, I. W. Tsang, and J. T. Kwok, “Improved nystrom low-rank approximation and error analysis,” in Proceedings of ICML, 2008, pp. 1232–1239.

P.-G. Martinsson, V. Rokhlin, and M. Tygert, “A randomized algorithm for the decomposition of matrices,” Applied and Computational Harmonic Analysis, vol. 30, no. 1, pp. 47–68, 2011.

Y. Yang, M. Pilanci, M. J. Wainwright et al., “Randomized sketches for kernels: Fast and optimal nonparametric regression,” The Annals of Statistics, vol. 45, no. 3, pp. 991–1023, 2017.

### Graph-based Models
### Deep Models
### Tree-based Models
## Optimization Approximation.
## Computation Parallelism.
## Hybrid Collaboration.
